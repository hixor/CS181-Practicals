{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fruit = pd.read_csv(\"fruit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = fruit[[\"width\",\"height\"]]\n",
    "y = fruit[\"fruit\"]\n",
    "Y = y-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 2)\n",
      "(59,)\n"
     ]
    }
   ],
   "source": [
    "print X.shape\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, eta, lambda_parameter):\n",
    "        self.eta = eta\n",
    "        self.lambda_parameter = lambda_parameter\n",
    "    \n",
    "    def oneHot(self, y, k=3):\n",
    "        base = np.array([np.ones(len(y)),]*k).transpose()\n",
    "        scale = np.array(range(1,k+1))\n",
    "        comp = base*scale\n",
    "        y_comp = np.array([np.array(y).transpose(),]*k).transpose()\n",
    "        self.y_mat = 1*np.equal(y_comp,comp)\n",
    "        return self.y_mat\n",
    "    \n",
    "    def softmax(self,mat,k):\n",
    "        exps = np.exp(mat)\n",
    "        denom = np.array([np.sum(exps,1), ]*k).transpose()\n",
    "        return exps/denom\n",
    "\n",
    "    # TODO: Implement this method!\n",
    "    def fit(self, X, C):\n",
    "        self.X = pd.DataFrame(X)\n",
    "        self.C = pd.DataFrame(C)\n",
    "        self.y = self.oneHot(self.C,3)\n",
    "        \n",
    "        n = self.X.shape[0]\n",
    "        m = self.X.shape[1]\n",
    "        k = 3\n",
    "        num_iters = 100\n",
    "        theta = np.zeros((m,k))\n",
    "        mat = np.dot(X,theta)\n",
    "        \n",
    "        for i in range(num_iters):\n",
    "            h = np.dot(X,theta) \n",
    "            probs = softmax(h,k)\n",
    "            grad = (float(1)/m)*np.dot(X.transpose(),y_mat - probs)/len(X) + (self.lambda_parameter/m)*theta\n",
    "            theta = theta - self.eta*grad\n",
    "        \n",
    "        return theta\n",
    "\n",
    "    # TODO: Implement this method!\n",
    "    def predict(self, X_to_predict):\n",
    "        # The code in this method should be removed and replaced! We included it just so that the distribution code\n",
    "        # is runnable and produces a (currently meaningless) visualization.\n",
    "        \n",
    "        h_pred = np.dot(X_to_predict,theta)\n",
    "        pred_probs = softmax(h_pred,k)\n",
    "        \n",
    "        return np.argmax(pred_probs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logis = LogisticRegression(0.001,1000)\n",
    "logis.oneHot(y,3)\n",
    "logis.fit(X,y)\n",
    "logis.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#One-hot encoding of y \n",
    "base = np.array([np.ones(len(fruit)),]*k).transpose()\n",
    "scale = np.array(range(1,k+1))\n",
    "comp = base*scale\n",
    "y_comp = np.array([np.array(y).transpose(),]*k).transpose()\n",
    "y_mat = 1*np.equal(y_comp,comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "alpha = 0.001\n",
    "lamb = 0\n",
    "J = 0\n",
    "\n",
    "n = X.shape[0]\n",
    "m = X.shape[1]\n",
    "k = num_classes\n",
    "theta = np.zeros((m,k))\n",
    "mat = np.dot(X,theta)\n",
    "\n",
    "def softmax(mat,k):\n",
    "    exps = np.exp(mat)\n",
    "    denom = np.array([np.sum(exps,1), ]*k).transpose()\n",
    "    return exps/denom\n",
    "\n",
    "baseline = softmax(mat,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta = np.zeros((m,k))\n",
    "mat = np.dot(X,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[-0.66666667  0.33333333  0.33333333]\n",
      " [-0.66666667  0.33333333  0.33333333]\n",
      " [-0.66666667  0.33333333  0.33333333]\n",
      " [-0.66666667  0.33333333  0.33333333]\n",
      " [-0.66666667  0.33333333  0.33333333]\n",
      " [-0.66666667  0.33333333  0.33333333]\n",
      " [-0.66666667  0.33333333  0.33333333]\n",
      " [-0.66666667  0.33333333  0.33333333]\n",
      " [-0.66666667  0.33333333  0.33333333]\n",
      " [-0.66666667  0.33333333  0.33333333]\n",
      " [-0.66666667  0.33333333  0.33333333]\n",
      " [-0.66666667  0.33333333  0.33333333]\n",
      " [-0.66666667  0.33333333  0.33333333]\n",
      " [-0.66666667  0.33333333  0.33333333]\n",
      " [-0.66666667  0.33333333  0.33333333]\n",
      " [-0.66666667  0.33333333  0.33333333]\n",
      " [-0.66666667  0.33333333  0.33333333]\n",
      " [-0.66666667  0.33333333  0.33333333]\n",
      " [-0.66666667  0.33333333  0.33333333]\n",
      " [ 0.33333333 -0.66666667  0.33333333]\n",
      " [ 0.33333333 -0.66666667  0.33333333]\n",
      " [ 0.33333333 -0.66666667  0.33333333]\n",
      " [ 0.33333333 -0.66666667  0.33333333]\n",
      " [ 0.33333333 -0.66666667  0.33333333]\n",
      " [ 0.33333333 -0.66666667  0.33333333]\n",
      " [ 0.33333333 -0.66666667  0.33333333]\n",
      " [ 0.33333333 -0.66666667  0.33333333]\n",
      " [ 0.33333333 -0.66666667  0.33333333]\n",
      " [ 0.33333333 -0.66666667  0.33333333]\n",
      " [ 0.33333333 -0.66666667  0.33333333]\n",
      " [ 0.33333333 -0.66666667  0.33333333]\n",
      " [ 0.33333333 -0.66666667  0.33333333]\n",
      " [ 0.33333333 -0.66666667  0.33333333]\n",
      " [ 0.33333333 -0.66666667  0.33333333]\n",
      " [ 0.33333333 -0.66666667  0.33333333]\n",
      " [ 0.33333333 -0.66666667  0.33333333]\n",
      " [ 0.33333333 -0.66666667  0.33333333]\n",
      " [ 0.33333333 -0.66666667  0.33333333]\n",
      " [ 0.33333333 -0.66666667  0.33333333]\n",
      " [ 0.33333333 -0.66666667  0.33333333]\n",
      " [ 0.33333333 -0.66666667  0.33333333]\n",
      " [ 0.33333333 -0.66666667  0.33333333]\n",
      " [ 0.33333333 -0.66666667  0.33333333]\n",
      " [ 0.33333333  0.33333333 -0.66666667]\n",
      " [ 0.33333333  0.33333333 -0.66666667]\n",
      " [ 0.33333333  0.33333333 -0.66666667]\n",
      " [ 0.33333333  0.33333333 -0.66666667]\n",
      " [ 0.33333333  0.33333333 -0.66666667]\n",
      " [ 0.33333333  0.33333333 -0.66666667]\n",
      " [ 0.33333333  0.33333333 -0.66666667]\n",
      " [ 0.33333333  0.33333333 -0.66666667]\n",
      " [ 0.33333333  0.33333333 -0.66666667]\n",
      " [ 0.33333333  0.33333333 -0.66666667]\n",
      " [ 0.33333333  0.33333333 -0.66666667]\n",
      " [ 0.33333333  0.33333333 -0.66666667]\n",
      " [ 0.33333333  0.33333333 -0.66666667]\n",
      " [ 0.33333333  0.33333333 -0.66666667]\n",
      " [ 0.33333333  0.33333333 -0.66666667]\n",
      " [ 0.33333333  0.33333333 -0.66666667]]\n"
     ]
    }
   ],
   "source": [
    "theta0 = np.zeros((m,k))\n",
    "mat0 = np.dot(X,theta0)\n",
    "baseline = softmax(mat0,k)\n",
    "#print baseline\n",
    "np.argmax(y_mat - baseline, axis=1)\n",
    "print np.argmax(baseline-y_mat,axis=1)\n",
    "print baseline-y_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "[[-0.00016667 -0.00284463  0.0030113 ]\n",
      " [ 0.001      -0.00181356  0.00081356]]\n",
      "[[-0.00416667 -0.07111582  0.07528249]\n",
      " [ 0.025      -0.04533898  0.02033898]]\n",
      "[[-0.00021783 -0.0053839   0.00560173]\n",
      " [ 0.00183225 -0.00361583  0.00178358]]\n",
      "[[-0.00544582 -0.13459744  0.14004327]\n",
      " [ 0.04580634 -0.09039581  0.04458947]]\n",
      "[[-0.00019457 -0.00766129  0.00785586]\n",
      " [ 0.002525   -0.0053741   0.0028491 ]]\n",
      "[[-0.00486426 -0.19153232  0.19639657]\n",
      " [ 0.06312509 -0.13435247  0.07122738]]\n",
      "[[-0.0001273  -0.00971108  0.00983839]\n",
      " [ 0.00309991 -0.00706551  0.0039656 ]]\n",
      "[[-0.00318261 -0.2427771   0.24595972]\n",
      " [ 0.07749782 -0.17663784  0.09914002]]\n",
      "[[ -3.83225488e-05  -1.15607513e-02   1.15990739e-02]\n",
      " [  3.57386765e-03  -8.67481555e-03   5.10094790e-03]]\n",
      "[[-0.00095806 -0.28901878  0.28997685]\n",
      " [ 0.08934669 -0.21687039  0.1275237 ]]\n",
      "[[  5.63085013e-05  -1.32327682e-02   1.31764597e-02]\n",
      " [  3.96028881e-03  -1.01925437e-02   6.23225486e-03]]\n",
      "[[ 0.00140771 -0.33081921  0.32941149]\n",
      " [ 0.09900722 -0.25481359  0.15580637]]\n",
      "[[ 0.00014527 -0.01474589  0.01460063]\n",
      " [ 0.00427008 -0.01161365  0.00734357]]\n",
      "[[ 0.00363164 -0.36864737  0.36501573]\n",
      " [ 0.10675189 -0.29034117  0.18358927]]\n",
      "[[ 0.00022083 -0.01611611  0.01589527]\n",
      " [ 0.00451228 -0.01293639  0.00842411]]\n",
      "[[ 0.0055208  -0.40290263  0.39738183]\n",
      " [ 0.11280708 -0.32340978  0.21060271]]\n",
      "[[ 0.00027802 -0.01735725  0.01707923]\n",
      " [ 0.0046946  -0.01416151  0.00946691]]\n",
      "[[ 0.00695046 -0.4339313   0.42698085]\n",
      " [ 0.11736501 -0.35403764  0.23667263]]\n",
      "[[ 0.00031388 -0.01848154  0.01816766]\n",
      " [ 0.00482369 -0.0152915   0.01046781]]\n",
      "[[ 0.00784705 -0.46203843  0.45419138]\n",
      " [ 0.12059226 -0.38228759  0.26169533]]\n",
      "[[ 0.000327   -0.01949985  0.01917284]\n",
      " [ 0.00490542 -0.01633016  0.01142473]]\n",
      "[[ 0.00817504 -0.48749614  0.4793211 ]\n",
      " [ 0.12263562 -0.40825395  0.28561833]]\n",
      "[[ 0.00031707 -0.02042198  0.02010491]\n",
      " [ 0.00494505 -0.01728208  0.01233704]]\n",
      "[[ 0.0079267  -0.51054955  0.50262286]\n",
      " [ 0.12362621 -0.43205212  0.30842591]]\n",
      "[[ 0.00028457 -0.02125684  0.02097227]\n",
      " [ 0.0049473  -0.01815243  0.01320513]]\n",
      "[[ 0.00711425 -0.531421    0.52430674]\n",
      " [ 0.12368238 -0.45381066  0.33012828]]\n",
      "[[ 0.00023055 -0.02201252  0.02178197]\n",
      " [ 0.00491647 -0.0189466   0.01403014]]\n",
      "[[ 0.00576387 -0.55031305  0.54454918]\n",
      " [ 0.12291164 -0.47366506  0.35075342]]\n",
      "[[ 0.00015644 -0.02269643  0.02253999]\n",
      " [ 0.00485648 -0.01967012  0.01481364]]\n",
      "[[ 0.00391101 -0.56741078  0.56349978]\n",
      " [ 0.1214121  -0.49175312  0.37034102]]\n",
      "[[  6.38758499e-05  -2.33153397e-02   2.32514638e-02]\n",
      " [  4.77093963e-03  -2.03284589e-02   1.55575193e-02]]\n",
      "[[ 0.0015969  -0.58288349  0.5812866 ]\n",
      " [ 0.11927349 -0.50821147  0.38893798]]\n",
      "[[ -4.53636064e-05  -2.38754416e-02   2.39208052e-02]\n",
      " [  4.66311614e-03  -2.09269227e-02   1.62638065e-02]]\n",
      "[[-0.00113409 -0.59688604  0.59802013]\n",
      " [ 0.1165779  -0.52317307  0.40659516]]\n",
      "[[-0.00016946 -0.0243824   0.02455186]\n",
      " [ 0.00453602 -0.02147062  0.0169346 ]]\n",
      "[[-0.00423641 -0.60956001  0.61379642]\n",
      " [ 0.11340039 -0.53676539  0.423365  ]]\n",
      "[[-0.00030659 -0.02484139  0.02514798]\n",
      " [ 0.00439238 -0.02196437  0.01757199]]\n",
      "[[-0.00766477 -0.62103469  0.62869946]\n",
      " [ 0.10980945 -0.54910927  0.43929982]]\n",
      "[[-0.00045501 -0.02525712  0.02571213]\n",
      " [ 0.0042347  -0.02241273  0.01817803]]\n",
      "[[-0.0113752  -0.63142795  0.64280314]\n",
      " [ 0.10586746 -0.56031819  0.45445073]]\n",
      "[[-0.00061303 -0.02563388  0.02624691]\n",
      " [ 0.00406524 -0.02281991  0.01875467]]\n",
      "[[-0.01532569 -0.64084707  0.65617276]\n",
      " [ 0.10163109 -0.57049786  0.46886677]]\n",
      "[[-0.00077907 -0.02597558  0.02675465]\n",
      " [ 0.00388606 -0.02318985  0.01930378]]\n",
      "[[-0.01947672 -0.64938952  0.66886624]\n",
      " [ 0.09715162 -0.57974616  0.48259453]]\n",
      "[[-0.00095166 -0.02628575  0.02723741]\n",
      " [ 0.00369901 -0.02352613  0.01982711]]\n",
      "[[-0.02379152 -0.65714369  0.68093521]\n",
      " [ 0.09247534 -0.58815315  0.49567781]]\n",
      "[[-0.00112945 -0.02656758  0.02769703]\n",
      " [ 0.00350575 -0.02383206  0.0203263 ]]\n",
      "[[-0.0282362  -0.66418957  0.69242577]\n",
      " [ 0.08764386 -0.59580139  0.50815753]]\n",
      "[[-0.00131119 -0.02682398  0.02813517]\n",
      " [ 0.00330778 -0.02411065  0.02080287]]\n",
      "[[-0.0327798  -0.67059944  0.70337924]\n",
      " [ 0.08269445 -0.60276617  0.52007172]]\n",
      "[[-0.00149577 -0.02705754  0.02855331]\n",
      " [ 0.00310642 -0.02436464  0.02125822]]\n",
      "[[-0.03739426 -0.67643848  0.71383274]\n",
      " [ 0.07766038 -0.60911597  0.5314556 ]]\n",
      "[[-0.00168217 -0.02727062  0.02895279]\n",
      " [ 0.00290285 -0.02459651  0.02169367]]\n",
      "[[-0.04205431 -0.68176539  0.7238197 ]\n",
      " [ 0.07257118 -0.61491286  0.54234168]]\n",
      "[[-0.0018695  -0.02746532  0.02933481]\n",
      " [ 0.00269812 -0.02480852  0.0221104 ]]\n",
      "[[-0.04673738 -0.68663296  0.73337033]\n",
      " [ 0.06745299 -0.62021292  0.55275993]]\n",
      "[[-0.00205694 -0.02764354  0.02970048]\n",
      " [ 0.00249315 -0.02500267  0.02250952]]\n",
      "[[-0.05142339 -0.69108854  0.74251194]\n",
      " [ 0.06232882 -0.62506674  0.56273792]]\n",
      "[[-0.00224379 -0.02780699  0.03005077]\n",
      " [ 0.00228875 -0.02518079  0.02289204]]\n"
     ]
    }
   ],
   "source": [
    "num_classes = 3\n",
    "alpha = 0.01\n",
    "lamb = float(50)\n",
    "J = 0\n",
    "\n",
    "theta = np.zeros((m,k))\n",
    "mat = np.dot(X,theta)\n",
    "\n",
    "for i in range(30):\n",
    "    mat = np.dot(X,theta) \n",
    "    probs = softmax(mat,k)\n",
    "    grad = (float(1)/m)*np.dot(X.transpose(),y_mat - probs)/len(X) + (lamb/m)*theta\n",
    "    print (lamb/m)*theta\n",
    "    theta = theta - alpha*grad\n",
    "    print theta\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.31535003  0.20810364  0.47654633]\n",
      " [ 0.3171418   0.21436594  0.46849226]\n",
      " [ 0.31848327  0.21621194  0.46530478]\n",
      " [ 0.31871987  0.21447223  0.46680791]\n",
      " [ 0.31869577  0.21754926  0.46375498]\n",
      " [ 0.31983617  0.21932218  0.46084165]\n",
      " [ 0.3189375   0.21580215  0.46526036]\n",
      " [ 0.31975154  0.21990985  0.46033861]\n",
      " [ 0.31823369  0.21363863  0.46812769]\n",
      " [ 0.31778136  0.21404492  0.46817371]\n",
      " [ 0.31770414  0.21462308  0.46767277]\n",
      " [ 0.31755776  0.2127213   0.46972095]\n",
      " [ 0.3177458   0.21280662  0.46944758]\n",
      " [ 0.31829614  0.21612616  0.4655777 ]\n",
      " [ 0.31848327  0.21621194  0.46530478]\n",
      " [ 0.31785793  0.21346787  0.4686742 ]\n",
      " [ 0.31826661  0.21487994  0.46685345]\n",
      " [ 0.31888254  0.2176352   0.46348226]\n",
      " [ 0.31709823  0.21009008  0.4728117 ]\n",
      " [ 0.32387726  0.24286295  0.43325978]\n",
      " [ 0.32442421  0.24519444  0.43038136]\n",
      " [ 0.32506978  0.2489882   0.42594202]\n",
      " [ 0.32483636  0.24817361  0.42699003]\n",
      " [ 0.32522841  0.25117305  0.42359855]\n",
      " [ 0.31058231  0.19051078  0.4989069 ]\n",
      " [ 0.31019591  0.19034643  0.49945766]\n",
      " [ 0.30882262  0.18757412  0.50360326]\n",
      " [ 0.31581339  0.20240899  0.48177762]\n",
      " [ 0.32060769  0.22219772  0.45719458]\n",
      " [ 0.31944293  0.21789282  0.46266425]\n",
      " [ 0.31904475  0.2164691   0.46448615]\n",
      " [ 0.31636435  0.20796139  0.47567426]\n",
      " [ 0.31927687  0.21906409  0.46165903]\n",
      " [ 0.31716973  0.20952045  0.47330982]\n",
      " [ 0.31721464  0.21074588  0.47203948]\n",
      " [ 0.3186095   0.21380926  0.46758124]\n",
      " [ 0.3189375   0.21580215  0.46526036]\n",
      " [ 0.31867042  0.21629769  0.46503189]\n",
      " [ 0.31842158  0.21372396  0.46785446]\n",
      " [ 0.32002262  0.21940815  0.46056923]\n",
      " [ 0.31904475  0.2164691   0.46448615]\n",
      " [ 0.31674288  0.20813073  0.47512639]\n",
      " [ 0.31906932  0.21772111  0.46320957]\n",
      " [ 0.31532828  0.19758793  0.48708379]\n",
      " [ 0.31472286  0.19562589  0.48965125]\n",
      " [ 0.31676639  0.20458416  0.47864945]\n",
      " [ 0.31513606  0.19750519  0.48735875]\n",
      " [ 0.31580532  0.20066448  0.48353021]\n",
      " [ 0.31527186  0.19813434  0.48659381]\n",
      " [ 0.32158287  0.21824959  0.46016754]\n",
      " [ 0.32151466  0.22009467  0.45839067]\n",
      " [ 0.3221915   0.22484421  0.45296429]\n",
      " [ 0.32199713  0.22220827  0.45579461]\n",
      " [ 0.32131168  0.21874946  0.45993886]\n",
      " [ 0.32091716  0.2173242   0.46175864]\n",
      " [ 0.32115495  0.22118739  0.45765766]\n",
      " [ 0.32189956  0.22153098  0.45656946]\n",
      " [ 0.31973726  0.21432041  0.46594233]\n",
      " [ 0.32132812  0.22000897  0.45866291]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#outs = np.equal(softie,np.amax(softie,axis=1))\n",
    "print probs\n",
    "np.argmax(probs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "X = np.array(fruit[[\"width\",\"height\"]])\n",
    "\n",
    "#TODO: One-Hot ENcode these y's\n",
    "y = np.array(fruit[\"fruit\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#init class #\n",
    "num_classes = 3\n",
    "alpha = 0.1\n",
    "J = 0\n",
    "\n",
    "n = X.shape[0]\n",
    "m = X.shape[1]\n",
    "k = num_classes\n",
    "theta = np.zeros((m,k))\n",
    "mat = np.dot(X,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = np.array([np.ones(len(fruit)),]*k).transpose()\n",
    "scale = np.array(range(1,k+1))\n",
    "comp = base*scale\n",
    "y_comp = np.array([np.array(y).transpose(),]*k).transpose()\n",
    "#print y_comp\n",
    "\n",
    "#THIS IS A ONE-HOT ENCODING OF THE ORIGINAL Y LABELS\n",
    "one_hot = 1*np.equal(y_comp,comp)\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def softmax(mat,k):\n",
    "    exps = np.exp(mat)\n",
    "    denom = np.array([np.sum(exps,1), ]*k).transpose()\n",
    "    return exps/denom\n",
    "\n",
    "# want to compute the gradient of the loss\n",
    "#def grad(mat,k):\n",
    " #   soft_grad = softmax(mat,k)*(1-softmax(mat,k))\n",
    "#   return soft_grad\n",
    "\n",
    "\n",
    "\n",
    "# now, update thetas depending on grad of loss?\n",
    "def update(grad,theta,eta):\n",
    "    updated = theta + eta*theta*grad # want this to be elementwise?\n",
    "\n",
    "softie = softmax(mat,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  0.33333333]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-18.69666667, -19.75      , -17.44666667],\n",
       "       [-19.78      , -20.88666667, -19.85333333]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = np.absolute(softie - one_hot)\n",
    "grad = np.matmul(X.transpose(),error)\n",
    "new_theta = theta - alpha*grad\n",
    "new_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#forward pass\n",
    "#1. Matrix Mult\n",
    "#2. Softmax trasfoooorm!\n",
    "\n",
    "#backward pass\n",
    "#1. Error compooping (softmax w/ \"correct\" of y subtracted)\n",
    "#2. Compooping gradient (input' * error (from 1))\n",
    "#2.5 Update grad\n",
    "\n",
    "#Wepeeet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#init class #\n",
    "num_classes = 3\n",
    "\n",
    "J = 0\n",
    "\n",
    "n = X.shape[0]\n",
    "m = X.shape[1]\n",
    "k = num_classes\n",
    "theta = np.zeros((m,k))\n",
    "mat = np.dot(X,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 2)\n",
      "(2, 3)\n",
      "(59, 3)\n"
     ]
    }
   ],
   "source": [
    "print X.shape\n",
    "#print y.shape\n",
    "#print mat.shape\n",
    "print theta.shape\n",
    "#print softie.shape\n",
    "print error.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.96666667, -33.56666667,  35.53333333],\n",
       "       [ 11.8       , -21.4       ,   9.6       ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_theta = np.dot(X.transpose(),error)\n",
    "new_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def softmax(mat,k):\n",
    "    exps = np.exp(mat)\n",
    "    denom = np.array([np.sum(exps,1), ]*k).transpose()\n",
    "    return exps/denom\n",
    "\n",
    "# want to compute the gradient of the loss\n",
    "#def grad(mat,k):\n",
    " #   soft_grad = softmax(mat,k)*(1-softmax(mat,k))\n",
    "#   return soft_grad\n",
    "\n",
    "# now, update thetas depending on grad of loss?\n",
    "def update(grad,theta,eta):\n",
    "    updated = theta + eta*theta*grad # want this to be elementwise?\n",
    "\n",
    "softie = softmax(mat,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.66666667,  0.33333333,  0.33333333],\n",
       "       [-0.66666667,  0.33333333,  0.33333333],\n",
       "       [-0.66666667,  0.33333333,  0.33333333],\n",
       "       [-0.66666667,  0.33333333,  0.33333333],\n",
       "       [-0.66666667,  0.33333333,  0.33333333],\n",
       "       [-0.66666667,  0.33333333,  0.33333333],\n",
       "       [-0.66666667,  0.33333333,  0.33333333],\n",
       "       [-0.66666667,  0.33333333,  0.33333333],\n",
       "       [-0.66666667,  0.33333333,  0.33333333],\n",
       "       [-0.66666667,  0.33333333,  0.33333333],\n",
       "       [-0.66666667,  0.33333333,  0.33333333],\n",
       "       [-0.66666667,  0.33333333,  0.33333333],\n",
       "       [-0.66666667,  0.33333333,  0.33333333],\n",
       "       [-0.66666667,  0.33333333,  0.33333333],\n",
       "       [-0.66666667,  0.33333333,  0.33333333],\n",
       "       [-0.66666667,  0.33333333,  0.33333333],\n",
       "       [-0.66666667,  0.33333333,  0.33333333],\n",
       "       [-0.66666667,  0.33333333,  0.33333333],\n",
       "       [-0.66666667,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333, -0.66666667,  0.33333333],\n",
       "       [ 0.33333333, -0.66666667,  0.33333333],\n",
       "       [ 0.33333333, -0.66666667,  0.33333333],\n",
       "       [ 0.33333333, -0.66666667,  0.33333333],\n",
       "       [ 0.33333333, -0.66666667,  0.33333333],\n",
       "       [ 0.33333333, -0.66666667,  0.33333333],\n",
       "       [ 0.33333333, -0.66666667,  0.33333333],\n",
       "       [ 0.33333333, -0.66666667,  0.33333333],\n",
       "       [ 0.33333333, -0.66666667,  0.33333333],\n",
       "       [ 0.33333333, -0.66666667,  0.33333333],\n",
       "       [ 0.33333333, -0.66666667,  0.33333333],\n",
       "       [ 0.33333333, -0.66666667,  0.33333333],\n",
       "       [ 0.33333333, -0.66666667,  0.33333333],\n",
       "       [ 0.33333333, -0.66666667,  0.33333333],\n",
       "       [ 0.33333333, -0.66666667,  0.33333333],\n",
       "       [ 0.33333333, -0.66666667,  0.33333333],\n",
       "       [ 0.33333333, -0.66666667,  0.33333333],\n",
       "       [ 0.33333333, -0.66666667,  0.33333333],\n",
       "       [ 0.33333333, -0.66666667,  0.33333333],\n",
       "       [ 0.33333333, -0.66666667,  0.33333333],\n",
       "       [ 0.33333333, -0.66666667,  0.33333333],\n",
       "       [ 0.33333333, -0.66666667,  0.33333333],\n",
       "       [ 0.33333333, -0.66666667,  0.33333333],\n",
       "       [ 0.33333333, -0.66666667,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333, -0.66666667],\n",
       "       [ 0.33333333,  0.33333333, -0.66666667],\n",
       "       [ 0.33333333,  0.33333333, -0.66666667],\n",
       "       [ 0.33333333,  0.33333333, -0.66666667],\n",
       "       [ 0.33333333,  0.33333333, -0.66666667],\n",
       "       [ 0.33333333,  0.33333333, -0.66666667],\n",
       "       [ 0.33333333,  0.33333333, -0.66666667],\n",
       "       [ 0.33333333,  0.33333333, -0.66666667],\n",
       "       [ 0.33333333,  0.33333333, -0.66666667],\n",
       "       [ 0.33333333,  0.33333333, -0.66666667],\n",
       "       [ 0.33333333,  0.33333333, -0.66666667],\n",
       "       [ 0.33333333,  0.33333333, -0.66666667],\n",
       "       [ 0.33333333,  0.33333333, -0.66666667],\n",
       "       [ 0.33333333,  0.33333333, -0.66666667],\n",
       "       [ 0.33333333,  0.33333333, -0.66666667],\n",
       "       [ 0.33333333,  0.33333333, -0.66666667]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = softie - one_hot\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-b9f6237d0d44>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-b9f6237d0d44>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    J = (1/m)*((-y)*log(h) - (1-y)'*log(1-h)) + lambda/(2*m) * theta(2:end)'*theta(2:end);\u001b[0m\n\u001b[0m                                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "mat = np.dot(X,theta)\n",
    "\n",
    "h = sigmoid(np.dot(X,theta));\n",
    "J = (1/m)*((-y)*log(h) - (1-y)'*log(1-h)) + lambda/(2*m) * theta(2:end)'*theta(2:end);\n",
    "grad = (1/m) * X'*(h - y) + lambda/m * [0;theta(2:end)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
