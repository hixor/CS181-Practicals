{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fruit = pd.read_csv(\"fruit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = fruit[[\"width\",\"height\"]]\n",
    "y = fruit[\"fruit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print X.shape\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, eta, lambda_parameter=0):\n",
    "        self.eta = eta\n",
    "        self.lambda_parameter = lambda_parameter\n",
    "        self.theta = None\n",
    "\n",
    "    def softmax(self,mat,k):\n",
    "        exps = np.exp(mat)\n",
    "        denom = np.array([np.sum(exps,1), ]*k).transpose()\n",
    "        return exps/denom\n",
    "\n",
    "    # TODO: Implement this method!\n",
    "    def fit(self, X, C):\n",
    "        X = np.column_stack((np.ones(len(X)), X))\n",
    "\n",
    "        \n",
    "        n = X.shape[0]\n",
    "        m = X.shape[1]\n",
    "        k = 3\n",
    "        num_iters = 1000\n",
    "        theta = np.zeros((m,k))\n",
    "\n",
    "        \n",
    "        for i in range(num_iters):\n",
    "            h = np.dot(X,theta) \n",
    "            probs = self.softmax(h,k)\n",
    "\n",
    "            deltas = probs - np.array(pd.get_dummies(C))\n",
    "            grad = np.dot(X.T, deltas)/len(X) + (self.lambda_parameter/m)*theta\n",
    "            theta = theta - self.eta*grad\n",
    "        self.theta = theta\n",
    "        \n",
    "        return self\n",
    "\n",
    "    # TODO: Implement this method!\n",
    "    def predict(self, X_to_predict):\n",
    "        # The code in this method should be removed and replaced! We included it just so that the distribution code\n",
    "        # is runnable and produces a (currently meaningless) visualization.\n",
    "        X_to_predict = np.column_stack((np.ones(len(X_to_predict)), X_to_predict))\n",
    "        h_pred = np.dot(X_to_predict, self.theta)\n",
    "        pred_probs = self.softmax(h_pred,3)\n",
    "        \n",
    "        return np.argmax(pred_probs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 2 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "0.627118644068\n"
     ]
    }
   ],
   "source": [
    "logis = LogisticRegression(.01,12)\n",
    "logis.fit(X,y)\n",
    "print logis.predict(X)\n",
    "print Counter(logis.predict(X) - (y-1))[0]/float(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 3 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0.0508474576271\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "lr = linear_model.LogisticRegression()\n",
    "lr.fit(X, y)\n",
    "print lr.predict(X)\n",
    "print Counter(lr.predict(X) -(y-1))[0]/float(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'popall'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-a9a6d6b99b7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, hold, data, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mgca\u001b[0;34m(**kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/matplotlib/figure.pyc\u001b[0m in \u001b[0;36mgca\u001b[0;34m(self, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/matplotlib/figure.pyc\u001b[0m in \u001b[0;36madd_subplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/matplotlib/axes/_subplots.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fig, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fig, rect, facecolor, frameon, sharex, sharey, label, xscale, yscale, axisbg, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_init_axis\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/matplotlib/axis.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, axes, pickradius)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/matplotlib/axis.pyc\u001b[0m in \u001b[0;36mcla\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/matplotlib/axis.pyc\u001b[0m in \u001b[0;36mreset_ticks\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'popall'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11194b610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:,0], X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#One-hot encoding of y \n",
    "base = np.array([np.ones(len(fruit)),]*k).transpose()\n",
    "scale = np.array(range(1,k+1))\n",
    "comp = base*scale\n",
    "y_comp = np.array([np.array(y).transpose(),]*k).transpose()\n",
    "y_mat = 1*np.equal(y_comp,comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "alpha = 0.001\n",
    "lamb = 0\n",
    "J = 0\n",
    "\n",
    "n = X.shape[0]\n",
    "m = X.shape[1]\n",
    "k = num_classes\n",
    "theta = np.zeros((m,k))\n",
    "mat = np.dot(X,theta)\n",
    "\n",
    "def softmax(mat,k):\n",
    "    exps = np.exp(mat)\n",
    "    denom = np.array([np.sum(exps,1), ]*k).transpose()\n",
    "    return exps/denom\n",
    "\n",
    "baseline = softmax(mat,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "theta = np.zeros((m,k))\n",
    "mat = np.dot(X,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "theta0 = np.zeros((m,k))\n",
    "mat0 = np.dot(X,theta0)\n",
    "baseline = softmax(mat0,k)\n",
    "#print baseline\n",
    "np.argmax(y_mat - baseline, axis=1)\n",
    "print np.argmax(baseline-y_mat,axis=1)\n",
    "print baseline-y_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "alpha = 0.01\n",
    "lamb = float(50)\n",
    "J = 0\n",
    "\n",
    "theta = np.zeros((m,k))\n",
    "mat = np.dot(X,theta)\n",
    "\n",
    "for i in range(30):\n",
    "    mat = np.dot(X,theta) \n",
    "    probs = softmax(mat,k)\n",
    "    grad = (float(1)/m)*np.dot(X.transpose(),y_mat - probs)/len(X) + (lamb/m)*theta\n",
    "    print (lamb/m)*theta\n",
    "    theta = theta - alpha*grad\n",
    "    print theta\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#outs = np.equal(softie,np.amax(softie,axis=1))\n",
    "print probs\n",
    "np.argmax(probs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "X = np.array(fruit[[\"width\",\"height\"]])\n",
    "\n",
    "#TODO: One-Hot ENcode these y's\n",
    "y = np.array(fruit[\"fruit\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#init class #\n",
    "num_classes = 3\n",
    "alpha = 0.1\n",
    "J = 0\n",
    "\n",
    "n = X.shape[0]\n",
    "m = X.shape[1]\n",
    "k = num_classes\n",
    "theta = np.zeros((m,k))\n",
    "mat = np.dot(X,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "base = np.array([np.ones(len(fruit)),]*k).transpose()\n",
    "scale = np.array(range(1,k+1))\n",
    "comp = base*scale\n",
    "y_comp = np.array([np.array(y).transpose(),]*k).transpose()\n",
    "#print y_comp\n",
    "\n",
    "#THIS IS A ONE-HOT ENCODING OF THE ORIGINAL Y LABELS\n",
    "one_hot = 1*np.equal(y_comp,comp)\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def softmax(mat,k):\n",
    "    exps = np.exp(mat)\n",
    "    denom = np.array([np.sum(exps,1), ]*k).transpose()\n",
    "    return exps/denom\n",
    "\n",
    "# want to compute the gradient of the loss\n",
    "#def grad(mat,k):\n",
    " #   soft_grad = softmax(mat,k)*(1-softmax(mat,k))\n",
    "#   return soft_grad\n",
    "\n",
    "\n",
    "\n",
    "# now, update thetas depending on grad of loss?\n",
    "def update(grad,theta,eta):\n",
    "    updated = theta + eta*theta*grad # want this to be elementwise?\n",
    "\n",
    "softie = softmax(mat,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "softie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "error = np.absolute(softie - one_hot)\n",
    "grad = np.matmul(X.transpose(),error)\n",
    "new_theta = theta - alpha*grad\n",
    "new_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#forward pass\n",
    "#1. Matrix Mult\n",
    "#2. Softmax trasfoooorm!\n",
    "\n",
    "#backward pass\n",
    "#1. Error compooping (softmax w/ \"correct\" of y subtracted)\n",
    "#2. Compooping gradient (input' * error (from 1))\n",
    "#2.5 Update grad\n",
    "\n",
    "#Wepeeet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#init class #\n",
    "num_classes = 3\n",
    "\n",
    "J = 0\n",
    "\n",
    "n = X.shape[0]\n",
    "m = X.shape[1]\n",
    "k = num_classes\n",
    "theta = np.zeros((m,k))\n",
    "mat = np.dot(X,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print X.shape\n",
    "#print y.shape\n",
    "#print mat.shape\n",
    "print theta.shape\n",
    "#print softie.shape\n",
    "print error.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_theta = np.dot(X.transpose(),error)\n",
    "new_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def softmax(mat,k):\n",
    "    exps = np.exp(mat)\n",
    "    denom = np.array([np.sum(exps,1), ]*k).transpose()\n",
    "    return exps/denom\n",
    "\n",
    "# want to compute the gradient of the loss\n",
    "#def grad(mat,k):\n",
    " #   soft_grad = softmax(mat,k)*(1-softmax(mat,k))\n",
    "#   return soft_grad\n",
    "\n",
    "# now, update thetas depending on grad of loss?\n",
    "def update(grad,theta,eta):\n",
    "    updated = theta + eta*theta*grad # want this to be elementwise?\n",
    "\n",
    "softie = softmax(mat,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "error = softie - one_hot\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mat = np.dot(X,theta)\n",
    "\n",
    "h = sigmoid(np.dot(X,theta));\n",
    "J = (1/m)*((-y)*log(h) - (1-y)'*log(1-h)) + lambda/(2*m) * theta(2:end)'*theta(2:end);\n",
    "grad = (1/m) * X'*(h - y) + lambda/m * [0;theta(2:end)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
